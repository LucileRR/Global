{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration de la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!conda install pandas #dans la console\n",
    "from datetime import date, timedelta\n",
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Racine des fichiers quotidiens\n",
    "BASE_URL = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/{}.csv'\n",
    "\n",
    "# Dates de diponibilité des fichiers\n",
    "START_DATE = date(2020, 1, 22)\n",
    "END_DATE = date(2020, 3, 27)\n",
    "\n",
    "#Répertoire de sauvegarde des fichiers bruts\n",
    "RAWFILES_DIR = '../data/raw/'\n",
    "PROCESSED_DIR = '../data/processed/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boucle de récupération des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = END_DATE - START_DATE       # as timedelta\n",
    "\n",
    "for i in range(delta.days + 1):\n",
    "    day = START_DATE + timedelta(days=i)\n",
    "    day_label = day.strftime(\"%m-%d-%Y\")\n",
    "    \n",
    "    \n",
    "    #virus_df = pd.read_csv(BASE_URL.format(day_label), sep=\",\", parse_dates=[\"Last Update\"])\n",
    "    \n",
    "    virus_df = pd.read_csv(BASE_URL.format(day_label), sep=',')\n",
    "    \n",
    "    # Files from 22 March have new column names\n",
    "    if ('FIPS' in virus_df.columns):\n",
    "        virus_df = pd.read_csv(BASE_URL.format(day_label), sep=',', parse_dates=['Last_Update'])\n",
    "        virus_df.columns = ['FIPS', 'Admin2', 'Province/State', 'Country/Region', 'Last Update', 'Latitude', \n",
    "                            'Longitude', 'Confirmed', 'Deaths', 'Recovered', 'Active', 'Combined_Key']\n",
    "    else:\n",
    "        virus_df = pd.read_csv(BASE_URL.format(day_label), sep=',', parse_dates=['Last Update'])\n",
    "    \n",
    "    # In new files, Mainland China is now China \n",
    "    virus_df['Country/Region'] = virus_df['Country/Region'].replace('Mainland China', 'China')\n",
    "    \n",
    "    # In data 3 ways of writting for South Korea\n",
    "    virus_df['Country/Region'] = virus_df['Country/Region'].replace('Korea, South', 'South Korea')\n",
    "    virus_df['Country/Region'] = virus_df['Country/Region'].replace('Republic of Korea', 'South Korea')\n",
    "\n",
    "    virus_df.to_csv(os.path.join(RAWFILES_DIR, day_label + '.csv'), index=False)\n",
    "    #print(day_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FIPS                     float64\n",
       "Admin2                    object\n",
       "Province/State            object\n",
       "Country/Region            object\n",
       "Last Update       datetime64[ns]\n",
       "Latitude                 float64\n",
       "Longitude                float64\n",
       "Confirmed                  int64\n",
       "Deaths                     int64\n",
       "Recovered                  int64\n",
       "Active                     int64\n",
       "Combined_Key              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "virus_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constitution de la table de référence lat/long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "df_list = []\n",
    "\n",
    "# Lecture des fichiers récupérés et sélection de ceux qui ont une lat / long\n",
    "for file in glob.glob(os.path.join(RAWFILES_DIR, '*.csv')):\n",
    "    virus_df = pd.read_csv(file, sep=',')\n",
    "    if 'Latitude' in virus_df.columns and 'Longitude' in virus_df.columns:\n",
    "        df_list.append(virus_df)\n",
    "\n",
    "all_df = pd.concat(df_list)\n",
    "\n",
    "# Table de référence pour les lat / long\n",
    "(all_df[[\"Province/State\", \"Country/Region\", \"Latitude\", \"Longitude\"]]\n",
    " # Delete where Latitude = 0 and Longitude = 0 for US and Canada\n",
    " .query('Latitude != 0 & Longitude != 0')\n",
    " .drop_duplicates(subset=[\"Province/State\", \"Country/Region\"])\n",
    " .sort_values(by=[\"Country/Region\", \"Province/State\"])\n",
    " .to_csv(os.path.join(PROCESSED_DIR, \"lat_long_table.csv\"), index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Province/State</th>\n",
       "      <th>Country/Region</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>South Korea</td>\n",
       "      <td>36.000</td>\n",
       "      <td>128.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Italy</td>\n",
       "      <td>43.000</td>\n",
       "      <td>12.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Henan</td>\n",
       "      <td>China</td>\n",
       "      <td>33.882</td>\n",
       "      <td>113.6140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Iran</td>\n",
       "      <td>32.000</td>\n",
       "      <td>53.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Heilongjiang</td>\n",
       "      <td>China</td>\n",
       "      <td>47.862</td>\n",
       "      <td>127.7615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2858</th>\n",
       "      <td>California</td>\n",
       "      <td>US</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2860</th>\n",
       "      <td>Delaware</td>\n",
       "      <td>US</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2866</th>\n",
       "      <td>Maryland</td>\n",
       "      <td>US</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2870</th>\n",
       "      <td>Nebraska</td>\n",
       "      <td>US</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>US</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3821 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Province/State Country/Region  Latitude  Longitude\n",
       "1               NaN    South Korea    36.000   128.0000\n",
       "2               NaN          Italy    43.000    12.0000\n",
       "4             Henan          China    33.882   113.6140\n",
       "8               NaN           Iran    32.000    53.0000\n",
       "15     Heilongjiang          China    47.862   127.7615\n",
       "...             ...            ...       ...        ...\n",
       "2858     California             US     0.000     0.0000\n",
       "2860       Delaware             US     0.000     0.0000\n",
       "2866       Maryland             US     0.000     0.0000\n",
       "2870       Nebraska             US     0.000     0.0000\n",
       "2879      Wisconsin             US     0.000     0.0000\n",
       "\n",
       "[3821 rows x 4 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(all_df[[\"Province/State\", \"Country/Region\", \"Latitude\", \"Longitude\"]]\n",
    " .drop_duplicates()\n",
    " [(all_df[[\"Province/State\", \"Country/Region\", \"Latitude\", \"Longitude\"]]\n",
    "   .drop_duplicates()\n",
    "   .duplicated(subset=[\"Province/State\", \"Country/Region\"], keep=False))]\n",
    ")\n",
    "# Les 3 pays qui ont \"bougé\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction d'une table unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_catalog = {\n",
    "    'Last Update':[\"<M8[ns]\"],\n",
    "    \"Confirmed\":[\"float64\", \"int64\"],\n",
    "    \"Deaths\":[\"float64\", \"int64\"],\n",
    "    \"Recovered\":[\"float64\", \"int64\"],\n",
    "    \"Latitude\":[\"float64\"],\n",
    "    \"Longitude\":[\"float64\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "latlong_df = pd.read_csv(os.path.join(PROCESSED_DIR, \"lat_long_table.csv\"))\n",
    "\n",
    "# Lecture des fichiers récupérés et sélection de ceux qui ont une lat / long\n",
    "for file in glob.glob(os.path.join(RAWFILES_DIR, '*.csv')):\n",
    "    virus_df = pd.read_csv(file, sep=',', parse_dates=[\"Last Update\"])\n",
    "    if not('Latitude' in virus_df.columns and 'Longitude' in virus_df.columns):\n",
    "        virus_df = virus_df.merge(latlong_df, on=[\"Province/State\", \"Country/Region\"], how='left')\n",
    "    \n",
    "    # Checker le type des variables dans l'importation de chaque fichier.\n",
    "    for field, types in data_catalog.items():\n",
    "        assert virus_df[field].dtypes in types, f\"bad type for {field} in {file}\"\n",
    "\n",
    "    df_list.append(virus_df.assign(source=os.path.basename(file)))\n",
    " \n",
    "all_df = pd.concat(df_list)\n",
    "\n",
    "# Sauvegarde de la table totale\n",
    "all_df.to_csv(os.path.join(PROCESSED_DIR, 'all_data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Projet Corona (Python)",
   "language": "python",
   "name": "corona"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
